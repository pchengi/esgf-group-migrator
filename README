This utility is a means to achieve smooth transitions when migrating attribute management
from one site to the other. Since a db dump brings all values including 'id' values which are 
unique, transfers needed 'clean' databases.  This tool however only copies relevant parts 
of the data from the database, discarding site-specific 'id' entries. The 'restore' part of
the operation is handled by a Python script which works with the output file generated by the 
'backup' program and writes out sql instructions to restore the entries. This makes for 
effortless transitions even across live sites with preexisting data. 
The database schema ensures that duplicate values are not pushed in and this tool ensures
 that required values are not left out! 


This utility needs passwordless login access to postgres.
The easiest way to set that up is to create a file in the home directory called '.pgpass' 
The contents of the file would be like this:
localhost:5432:esgcet:dbsuper:<password>

Ensure that the permissions on the file are set to 600.


Backing up:

backup.sh requires two arguments:
1. group id for the group you want to backup.
2. output file name for raw user data output

eg: bash backup.sh 6 cmip5research.out

The output file(s), i.e one file per group, are what need to be sent to the admin managing the 
site where the data needs to be ingested.


Restoring:

restore.sh requires three arguments:
1. group id of the local group into which data is to be ingested.
2. role id on local machine for 'user' role.
3. input file for ingestion

eg: bash restore.sh 7 6 cmip5research.out


Important:
1. Export Postgres home with PGPATH. example: export PGPATH=/usr/local/psql
2. You may see lines such as the following in the output. They are perfectly normal and is 
NOT a cause for concern. 

psql:restoreusers.sql:96: ERROR:  duplicate key value violates unique constraint "user_openid_key"
psql:restoreperms.sql:1: ERROR:  duplicate key value violates unique constraint "permission_pkey"

